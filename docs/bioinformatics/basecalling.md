# Nanopore sequencing base calling and quality control

---

## Introduction

In this session we are going to be looking at data generated by third-generation nanopore sequencing technology. Developed by Oxford Nanopore Technologies (ONT), these platforms, rather than the next-generation 'sequencing-by-synthesis approach', make use of an array of microscopic protein ‘pores’ set in in an electrically resistant membrane which guide strands of DNA or RNA through them. Each nanopore corresponds to its own electrode connected to a channel and sensor chip, which measures the electric current that flows through the nanopore. When a molecule passes through a nanopore, the current is disrupted to produce a characteristic ‘squiggle’. The squiggle is then decoded using basecalling algorithms to determine the DNA or RNA sequence in real time. Oxford Nanopore’s most popular platform is the MinION which is capable of generating single reads of up to 2.3 Mb (2.3 million bases).

![Nanopore animation](../img/sequencing_animation.gif)  

The MinION is one of 5 scalable platforms developed by ONT. High-throughput applications such as the GridION and PromethION use an array of nanopore flowcells to produce between 5 to 48 times more data than the MinION alone – outputting up to 48 TB of data in one run. More downscaled solutions such as The Flongle and SmidgION use a smaller, single flowcell to generate data. The MinION is a highly portable sequencing platform, about the size of a large USB flash drive. This technology enables researchers to perform sequencing analyses almost anywhere, providing they have the correct equipment to prepare the DNA libraries and analyse the output data. 

![devices](../img/nanopore-devices.jpeg) 

A complete sequencing run on the MinION platform can generate as much as 1 terabyte of raw data, and downstream analyses require a significant amount of compute power – multicore high performance processors and large amounts of RAM. This poses a significant logistical challenge for researchers who want to take advantage of the platform’s portability aspect. Over recent years, the integration of [GPUs](https://en.wikipedia.org/wiki/Graphics_processing_unit)(graphics processing units) in to analysis workflows has sped up applications involving machine learning greatly. 

![diagram](../img/pipeline_diagram.png) 

## Activity Briefing
Today we will be working with example data, as detailed in the _data_section. Today, we are going to take this raw data and generate some insights to help further understand your MTB samples.  In this session today, we will:

* Basecall your data, transforming it from squiggle to bases.
* Perform quality control on the data, ensuring our data is of sufficient quality for analysis.
* Map the reads to a reference genome, producing three genomic 



## Basecalling
To convert the raw data output produced by the MinION sequencing run in to a usable form we need to perform a process called basecalling. This converts the raw electronic signal which is collected as the DNA passes through the pore, in to base reads – A, C, T or G. To do this we will use a program called Guppy – a software package designed by ONT which uses [recurrent neural nets (RNN)](https://en.wikipedia.org/wiki/Recurrent_neural_network) to interpret the raw signal, which comes in a proprietary '.fast5' format file produced by the sequencer software and convert it in to the standard .fastq format, for use downstream in our pipeline. Users also have the choice of using the experimental [Dorado](https://github.com/nanoporetech/dorado) basecaller which gives the option of training specialised models for specific basecalling applications. As mentioned above, GPUs are used to accelerate the basecalling process. Without a GPU performing basecalling becomes a very slow process, therfore it is advised that users procure a machine with a compatable Nvidia GPU (more information on this here).

![diagram](../img/gpu_diagram.png) 






Activate the relevant conda environment, navigate to the `~/data/ATMB/` basecalling folder in the home directory, and we’ll start the first step.
!!! info
    IMPORTANT: Every time you open a new terminal window, you must re-activate the nanopore conda environment.
    conda activate nanopore
`conda activate nanopore`

`cd ~/data/ATMB/basecalling/raw_fast5_reads/ `

Use the `ls` command to see what is inside this folder. Use `head` to preview one of the fast5 files. As you might find, it's completely unreadable. This is because at this stage, the data is in a binary format representing the squiggle signal we spoke about previously. We need to basecall this data before we can use it.

 Basecalling can be performed in a number of ways. There is an option to perform this while sequencing in the MinKNOW GUI, however this software provides fewer options in the ways basecalling can be completed. Here, we will use Guppy for maximum flexibility. Since the machines we are working on do not have a GPU available we will have to use the two CPU cores available to us. Therefore, we will only basecall a subset (<1%) of the dataset as an example, and in the subsequent steps we will use a pre-basecalled output. Copy the whole line in to the terminal and execute the command:

```
guppy_basecaller --config ~/ont-guppy/data/dna_r10.4.1_e8.2_400bps_fast.cfg --trim_adapters --detect_barcodes --compress_fastq  --input_path ~/data/ATMB/basecalling/raw_fast5_reads  --save_path ~/data/ATMB/basecalling/fastq
```

        
 You should now see the bascalling process begin, and a progress bar appear. This may take some time depending on the performance of your machine.

When the process in completed, you will find the basecalled reads in a .fastq formatted file. Navigate there by typing the following in to the terminal:  
`cd ~/data/ATMB/basecalling/fastq/pass`

Use the `ls` command to see what is inside this folder. This directory holds the fastq formatted 'pass' reads  from the basecalling process. The reads have a quality score > 7. Use  zcat FILENAME | head to preview the compresssed fastq file. Unlike the fast5 files, these are human-readable and contain all of the read data required for downstream analyses. Can you identify any of the common elements of a .fastq format files - similar to the ones you may have encountered in previous sessions? Click here to find out more about the [FASTQ](https://en.wikipedia.org/wiki/FASTQ_format) format.


## Basecalling - Quality Control
Before moving on to the analysis steps, it is important to gauge the quality of your sequencing output. There are numerous factors which dictate the quality of the output data, spanning between quality of the input material, library preparation to software and hardware failure. We will look at some important metrics produced by the sequencer which will give us a feel for how well the run went.
In order to get the run metrics in to a useful form, we will use an pycoQC to produce a range of plots in a HTML output, which we will use to judge the quality of the sequencing run. Something to note, is that in this activity we will only use a small subset of the sequenced reads, or else the analysis would take all day. This subsetting means that the sequencing telemetry may look inconsistent, when compared to a full run.

```
pycoQC -f ~/data/ATMB/basecalling/fastq/.sequencing_summary.txt -o ~/data/ATMB/basecalling/fastq/pycoqc_results.html
```

After executing the command you should find a file called 'pycoqc_results.html'. Open them up in the file manager or in the terminal (with the below command) and inspect some of the plots and see what you can find out. As mentioned, the data here are only a small subset of reads, so some of the plots are incomplete. But this should give you a good idea of how this analysis should look.
        
`firefox ~/data/ATMB/basecalling/fastq/pycoqc_results.html`

Before continuing, quit firefox by clicking the X in the top right corner of the web-browser window.

!!! question "Exercise 1"

    === "Question"
        Approximately how long did the sequencing run take?

    === "Answer"        
          
        You can find the answer in the 'General run summary' table.
        
        10.09 hours
            

!!! question "Exercise 2"

    === "Question"
        What is the N50 of the *passed* reads (>Q7) for all basecalled reads in this run?

    === "Answer"        
          
        Try looking at the table at the top of the pycoQC report. Be sure to find the 'Passed' read section.
        
        XXX
          



## Adapter Trimming
Nanopore library preparation results in the addition of a sequencing adapter at each end of the fragment. Both the template and complement strands to be sequenced carry the motor protein which means both strands are able to translocate the nanopore. For downstream analysis, it is important to remove these adapters. For this we will use Porechop. This program processes all of the reads in our basecalled fastq file, and removes these adapter sequences. Furthermore, the ligation library prep process can result in conjoined reads, meaning an adapter will be found in the middle of an extra-long read. Porechop will identify these, split them and remove the adapters. In addition, if you use a multiplexing kit to maximise sample throughput, this program will split the reads based on the molecular barcode added to each sample. Our dataset only has one sample, so this demultiplexing won't be necessary. 

Let's launch porechop and remove the adapters from the basecalled fastq files. The RAP and DMSO files have already been done for you. First move up one directory, to where we have put the pre-basecalled files for you, then launch the command below that to run porechop on the WT dataset:

cd ~/data/ATMB/basecalling/fastq
porechop -i ~/data/ATMB/basecalling/fastq/WT.fastq.gz -o WT.porechop.fastq
Read the output of the terminal to understand better what porechop is doing to the dataset. Ask a demonstrator if you have any questions about this.

Kraken QC
Another method of quality control is to check our reads for sequence contamination from other 'off-target' organisms. This is important in order to firstly, understand how effective your DNA extraction, enrichment and sequencing was. And secondly, to prevent anomalous reads from being incorporated in to assemblies.
Using our basecalled reads we will perform an analysis using Kraken. Kraken is a tool which sifts through each read in a .fastq file and crosschecks it against a database of microorganism genomes. The output is a taxonomic assignment of each read, enabling to identify if any contamination has occurred. In this case we will be looking for any reads which do not belong to the Plasmodium knowlesi genome.
Let’s navigate to the kraken folder to begin the analysis:
cd ~/data/ATMB/kraken
The following line of code is composed of these elements:
Kraken – calling the Kraken executable
kraken --db ~/data/ATMB/kraken/KDB/ - this points kraken to a vast sequence database of relevant microorganisms to cross-check our reads against
--output temp.krak – this argument locates the output file
WT.porechop.fastq.gz – this argument locates the input file
        
As before, to save time, we will run Kraken on only one sample. Type the following command in to the terminal to unleash the Kraken:
kraken --db ~/data/ATMB/kraken/KDB/ --output temp.krak ~/data/ATMB/basecalling/fastq/WT.fastq.gz

This file isn't particularly easy to interpret, so we will use a program called Recentrifuge to transform these data in to a more human-readable format.
rcf -k temp.krak -o kraken_output.rcf.html --nodespath ./taxdump
Try opening the HTML file generated by recentrifuge in a web browser, what can you tell about the sequencing run? Was is successful? Note - due to constraints with the virtual machine, we have generated an alternative report, which can be loaded using the below command. Copy and paste it in to the terminal. If you have any questions about this, ask a demonstrator.
firefox .kraken_output.rcf.html

          Can you see any contaminating reads? What is the majority off target organism, and why do you think it is present in our dataset?
        

Question 3


Can you see any contaminating reads? What organism(s) is/are there?

Dengue virus



False: Open up temp.krak.rcf.full.html in firefox and browse the results
              


Homo sapiens



True: Right answer, well done!
              




Mapping and Visualisation
Now that we have verified a successful sequencing run, our basecalled and trimmed Plasmodium-confirmed data are ready to go, we will now map the reads on to a reference genome and perform variant calling.

Mapping tools are not to be confused with other sequence alignment tools, such as clustalO or MUSCLE. These are designed for a totally different use case and input data. Using these will not work on whole-genome read data.


Move to the mapping directory:
cd ~/data/ATMB/mapping
Now we can use minimap2 to align our QC completed, porechopped reads. Minimap2 is an alignment tool specifically designed to map error-prone nanopore reads. You might have used an alignment tool previously, such a BWA. You can find more information about this tool by clicking the link comparing the two alignment tools
minimap2 -ax map-ont ~/data/ATMB/mapping/Pknowlesi_A1H1_WT_DiCre.fa ~/data/ATMB/basecalling/fastq/DMSO.porechop.fastq > DMSO_alignment.sam

As before, we now need to convert our alignment .sam file in to a .bam formatted file:
samtools view -q 10 -b -S DMSO_alignment.sam > DMSO_alignment.bam
Next, we need to sort the .bam formatted file:
samtools sort DMSO_alignment.bam -o DMSO_sorted.bam
Finally we need to index the sorted bam file:
samtools index DMSO_sorted.bam
Repeat each of the above mapping steps, from the first minimap2 command for the RAP and WT lines. Be sure to modify each command to have the correct input and output lines. 

Samtools has a function to assess the quality of an alignment called flagstat. Issue the below command, being sure to run it on the SAM file from the first mapping step, and record the output for your manuscript. What do you make of the output? The percentage of mapped reads is less than 100%, why do you think that is? 
samtools flagstat DMSO_alignment.sam

Visualisation using IGV
Now that we have successfully mapped the reads to a reference we can visualise them in IGV to get a closer look at what our sequencing data looks like. We also add the GFF file for our genome. This contains all of the annotation metadata, such as gene names, coding regions etc. 
The Integrative Genomics Viewer (IGV) is a high-performance, easy-to-use, interactive tool for the visual exploration of genomic data. It is a staple for the bioinformatician when assessing genome alignments from whole genome sequencing data. 

Open IGV from the terminal:
        
igv

Go to the 'Genomes' dropdown at the top of the IGV window, load a genome from file, navigate to /home/user/data/ATMB/mapping by copying the bold text in to the 'File name' field and select Pknowlesi_A1H1_WT_DiCre.fa.  From the 'File' dropdown, open your sorted and indexed BAM file from the mapping steps by choosing 'Load from file', and navigate to the same mapping directory and choose, for example, 'DMSO_sorted.bam'. Finally, from the same directory and menu, open 'PknowlesiA1H1.gff'.
        


Now that you have loaded the reference genome, the BAM read alignment and the GFF annotation track, your IGV window should look a little bit like the image below. Explore the functions of IGV and browse the Pk A1H1 genome.  



            If you are curious how GFF annotations work, you can view the raw data by entering the below command in to a new terminal window. The head -n 100 command will show the first 100 lines of content of a given filename in the terminal windoww, providing it is human readable text, and not binary or compressed data. To learn more about the GFF format, follow this link

head -n 100 ~/data/ATMB/mapping/PknowlesiA1H1.gff 


          An important aspect of an effective nanopore sequencing analysis is being able to differentiate between errors, caused by the inherent error-prone nature of nanopore sequencing, and true SNPs. Configure IGV to the maximum zoom on the read view (top right corder slider). You should see something similar to the image below. You can see that there are random errors dotted around the read panel. Some positions in the alignment will have multiple reads supporting SNPs in the same location. These are possibly the variants we are looking for, and the key to unlocking our sequence data. These columns represent positions which have a high frequency of basecalls which do not agree with the reference sequence. It is unlikely that random errors will appear in such a manner, and so, in our next analysis we will use a program to scan our alignment and identify these high frequency variants in a process called ‘variant calling’, which we will cover in the next activity.
        



Minimise the IGV window, leave open the terminal which launched it. Open a new terminal, activate the nanopore environment and move to the next steps.
Variant Calling

conda activate nanopore

          Variant calling is a process used to identify new genotypes based on the ‘differences’ found our read data. In this case, we are going to be using the alignment you have just generated to compile a database of SNPs and indels, inferred from positions which have a majority allele which is different from the one found on the reference sequence.
        


        Navigate to the ‘variant_calling’ folder and we’ll begin:
        
cd ~/data/ATMB/variant_calling 
We will use a variant caller called freebayes. Freebayes is a Bayesian genetic variant detector designed to find small polymorphisms, specifically SNPs (single-nucleotide polymorphisms), indels (insertions and deletions), MNPs (multi-nucleotide polymorphisms), and complex events (composite insertion and substitution events) smaller than the length of a short-read sequencing alignment.
freebayes -f ~/data/ATMB/mapping/Pknowlesi_A1H1_WT_DiCre.fa ~/data/ATMB/mapping/DMSO_sorted.bam -F 0.5 -C 10 -r LT727654:329600-329932 -u  > DMSO_variants.vcf 

-F – This command tells the program the location of the reference file, so the procram can compare the alignment against it inorder to make the calls.
-F  – specifies the minimum frequency of a call. To eliminate errors, we set this to 0.5. That means that 50% of the reads have to agree with a particular alternative allele (variant)
-C – specifies the minimum read depth of a variant call. (More on this later)
-r  – specifies the region in the genome to be called. We can not perform variant calling on the whole genome bacause it would take a very long time, and a more powerful computer.
Once the variant callerhas finished, take a look inside the VCF file to see what kind of data it contains:
tail -n 3 DMSO_variants.vcf 
Check out this page to understand the structure of a VCF file
Go back to IGV and load the VCF in to the window by navigating to the ATMB/variant_calling folder through the File>Load from file menu, and selecting DMSO_variants.vcf
Navigate to the locus of the variant by copying LT727654:329600-329632 in to the navigation form. You should see something like that in the image below:

Question 4


Are the SNPs in a coding region? Check the GFF track. Zoom out to about 50% if you have any doubts.

Yes. It's MSP1.



False: Zoom out to 50% to see if you can notice another gene on the GFF track.
              


No, it's not in a protein-coding region.



True: Right answer, well done! The closes gene is PKA1H_070011100.1.
              





            Because we are working with a lab strain, there are likely few SNPs, as this reference is very closely related to the isolates we have sequenced. In future experiments however, it is very important to perform variant calling to identify possible genotypes that might confer drug resistance or SNPs that might be used for tracking transmission.
          
Validation of PvDBP excision
Now load the other two BAMs you mapped in to IGV, using the same method you used to load the DMSO sample. Load the RAP.sorted.bam and the WT.sorted.bam files. Adjust the display ratios by dragging the partitions beteen the three BAM tracks and zoom out to 50% using the zoom slider in the top right corner. Have a look at the video below if you need help. 



In to the navigation form at the top of the IGV window, enter PKA1H_060029200, this is a unique desegnation assigned to the Plasmodium knowlesi erythrocyte binding protein, the locus in the genome you have been working with throughout the module. You can find more information on this by visiting its PlasmoDB page.
Here, you should be able to visualise all three of your alignments and compare them. What do you make of the coverage on each sample? Why do you think they appear in the way that they do?
Right click the coverage plot for each BAM track and save the image to the user space, with the name of the track and your own name. I will put a link up on the board for you to upload this image, so that you can include it as a figure in your manuscript write-up.


Optional extra activity - mapping DMSO to Pknowlesi_A1H1_WT_DiCre_PvDBP pseudogenome 
Now that we have inferred the insertion of a floxed PvDBP into the PkDBPα locus and successful DiCre-mediated excision of the floxed region, we can confirm it by re-mapping our read data to a new reference sequence. This reference sequence contains the PvDBP ortholog gene insead of the WT PkDBP. In this section, you will repeat the above steps, but this time, using the Pknowlesi_A1H1_WT_DiCre_PvDBP.fa reference, which can be found in the 'mapping' folder. Importantly, you need to switch out the reference sequence when mapping, and be sure to change the names of the inputs and the output files to reflect that they are mapped against the PvDBP pseudogenome. Below is a hint to get you started:
minimap2 -ax map-ont ~/data/ATMB/mapping/Pknowlesi_A1H1_WT_DiCre_PvDBP.fa ~/data/ATMB/basecalling/fastq/DMSO.porechop.fastq > DMSO_alignment_PvDBP.sam
Once you have remapped the three sequence datasets, open up a new IGV window, load the correct Pknowlesi_A1H1_WT_DiCre_PvDBP.fa reference genome, the GFF and the three new PvDBP alignments and compare them with the other IGV window, with the wild-type alignments. What can you infer from the differences in the alignments?


Optional extra activity 2 - Generating coverage plots using R

             Two key metrics are often required for asessing the success of sequenceing, and confirming the presence of any structural varaints such as those resulting from the excision of genes. These metrics are reference coverage and read depth. Genome coverage tells us the percentage of the reference which has had sequencing reads aligned to it, which allows us to identify any regions that may have not been successfully sequenced. Depth is an equally as important metric: it tells us how many inidividual reads have mapped to the same position. This is a particularly important statistic if you intend on doing variant calling, as regions with low depth may fall prey to false calls due to the random errors we have in our nanopore data. With a high enough read depth, we can be fairly sure that these errors will be ignored. If you find this confusing, think of the alignment as a 2-dimentional plot. The X-axis is the length of the genome, this relates to coverage. The depth is the Y-axis, how deep the reads are at a given position.
        

A tool we can use to asess the depth and coverage of an alignment is Samtools; a versatile package used in all facets of genomics. We will extract the depth statistics from the .bam alignment file we generated in the previous sections. This will generate a file called ‘depth_statistics_XXXX’. Samtools will scan across the alignment counting how many reads have mapped to each base in the genome.
samtools depth -a -r LT727653:1040496-1050000 ~/data/ATMB/mapping/DMSO_sorted.bam > depth_statistics_DMSO
Take a look at the depth_statistics file using the head command. Repeat this process for all of your alignments, making sure to change the input and output names for the 'samdools depth' command.
Next, we will use the R statistical package to generate a plot based on the data samtools generated. Simply type ‘R’ in to the terminal to initialise the R command interface. 
conda activate nanopore
cd ~/data/ATMB/mapping
featherpad &
R

Once you have initialised R, you can enter the following lines of code by copying and pasting them in to the R terminal instance. Be sure to change the bold sections in the below code to reflect the files you generated with samtools. Make sure the 'Dataset' names are replaced with the correct isolate name. Open up a notepad and copy the code below. Edit the code in the notepad to contain the correct labels, then copy it in to the R window.
# Load the packages
library(gridExtra)
library(ggplot2)

# Load the data
data1 <- read.table("depth_statistics_DMSO", sep="\t", header=FALSE, col.names=c("Contig","Position", "Depth"))
data2 <- read.table("depth_statistics_RAP", sep="\t", header=FALSE, col.names=c("Contig","Position", "Depth"))
data3 <- read.table("depth_statistics_WT", sep="\t", header=FALSE, col.names=c("Contig","Position", "Depth"))

# Create the plots
p1 <- ggplot(data1, aes(x=Position, y=Depth)) + geom_line(color="blue") + ylim(0,50) + ggtitle("Dataset 1") +
  annotate("segment", x=1043441, xend=1047350, y=30, yend=30, arrow=arrow(length=unit(0.4,"cm")), color="black") +
  annotate("text", x=1045441, y=36, label="Gene name", color="black")

p2 <- ggplot(data2, aes(x=Position, y=Depth)) + geom_line(color="red")+ ylim(0,50)  + ggtitle("Dataset 2")+
  annotate("segment", x=1043441, xend=1047350, y=30, yend=30, arrow=arrow(length=unit(0.4,"cm")), color="black") +
  annotate("text", x=1045441, y=36, label="Gene name", color="black")

p3 <- ggplot(data3, aes(x=Position, y=Depth)) + geom_line(color="green")+ ylim(0,50)  + ggtitle("Dataset 3")+
  annotate("segment", x=1043441, xend=1047350, y=30, yend=30, arrow=arrow(length=unit(0.4,"cm")), color="black") +
  annotate("text", x=1045441, y=36, label="Gene name", color="black")


# Combine the plots and adjust the layout
gridExtra::grid.arrange(p1, p2, p3, ncol=1)

# Save plots to a PNG file
g <- arrangeGrob(p1, p2, p3, nrow=3)
ggsave(file="coverage_plt.png", g)

You can quit R by typing:
quit()
Well done!
